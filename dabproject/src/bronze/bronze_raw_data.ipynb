{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f9f5b77-a795-415f-923d-c71485e2caa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Unclean sample data\n",
    "raw_data = [\n",
    "    Row(id=1, name=' Alice ', age='30', department=' HR ', salary='50000', email=' alice@example.com '),\n",
    "    Row(id=2, name='Bob', age='25', department=None, salary='60000', email='bob@example.com'),\n",
    "    Row(id=None, name='Charlie', age='35', department='Finance', salary='70000', email='charlieatexample.com'),  # invalid email\n",
    "    Row(id=4, name='David', age=None, department='Marketing', salary='55000', email='david@example.com'),\n",
    "    Row(id=5, name=' Eva', age='twenty', department='Sales', salary='45000', email='eva@example.com'),\n",
    "    Row(id=6, name='Tom', age='29', department='IT', salary='62000', email='  ')  # empty email\n",
    "]\n",
    "\n",
    "raw_df = spark.createDataFrame(raw_data)\n",
    "raw_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "413d8c3d-403f-4937-bfe0-9d3ec75f9e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_df.createOrReplaceTempView(\"employee\")\n",
    "spark.sql(\"SELECT * FROM employee\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "530157be-4b29-4e83-af60-2b94082f4e6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create or replace a managed table named 'raw_employee_data' from raw_df\n",
    "raw_df.write.mode(\"overwrite\").saveAsTable(\"assertbundles.bronze.raw_employee_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e16b445f-eb1f-4bb7-9a86-d0c2038c82cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = spark.read.table(\"assertbundles.bronze.raw_employee_data\")\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_raw_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
